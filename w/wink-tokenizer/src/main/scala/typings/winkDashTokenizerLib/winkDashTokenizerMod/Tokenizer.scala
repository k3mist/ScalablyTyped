package typings
package winkDashTokenizerLib.winkDashTokenizerMod

import scala.scalajs.js
import scala.scalajs.js.`|`
import scala.scalajs.js.annotation._

trait Tokenizer extends js.Object {
  /**
  	 * Defines the configuration in terms of the types of token that will be extracted by tokenize() method.
  	 * Note by default, all types of tokens will be detected and tagged automatically.
  	 * @param config configuration object
  	 * @returns number of true parameters
  	 */
  def defineConfig(config: winkDashTokenizerLib.winkDashTokenizerMod.TokenizerNs.Config): scala.Double
  /**
  	 * Returns the finger print of the tokens generated by the last call to tokenize().
  	 * A finger print is a string created by sequentially joining the unique code of each token's type.
  	 *
  	 * currency: 'r', email: 'e', emoji: 'j', emoticon: 'c',
  	 * hashtag: 'h', number: 'n', ordinal: 'o',
  	 * punctuation: token becomes fingerprint,
  	 * quoted_phrase: 'q', symbol: token becomes fingerprint,
  	 * time: 't', mention: 'm', url: 'u', word: 'w',
  	 * @return string of token types
  	 */
  def getTokensFP(): java.lang.String
  /**
  	 * Tokenize a string
  	 * @param sentence to be tokenized
  	 * @returns tokens
  	 */
  def tokenize(sentence: java.lang.String): js.Array[winkDashTokenizerLib.winkDashTokenizerMod.TokenizerNs.Token]
}

object Tokenizer {
  @scala.inline
  def apply(
    defineConfig: js.Function1[winkDashTokenizerLib.winkDashTokenizerMod.TokenizerNs.Config, scala.Double],
    getTokensFP: js.Function0[java.lang.String],
    tokenize: js.Function1[
      java.lang.String, 
      js.Array[winkDashTokenizerLib.winkDashTokenizerMod.TokenizerNs.Token]
    ]
  ): Tokenizer = {
    val __obj = js.Dynamic.literal(defineConfig = defineConfig, getTokensFP = getTokensFP, tokenize = tokenize)
  
    __obj.asInstanceOf[Tokenizer]
  }
}

